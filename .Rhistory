library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
length(huegenots.data[,1])
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
length(Y)
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
c(which(is.na(poploss_keyser) == FALSE))
huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
huegenots.data <- huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data <- huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
lenght(Y)
length(Y)
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data <- huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
# huegenots.data <- huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
huegenots.data <- huegenots.data[-(which(is.na(poploss_keyser) == FALSE))]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
huegenots.data
poploss_keyser_projected
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
# huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
dim(huegenots.data)
huegenots.data <- huegenots.data[-1,]
dim(huegenots.data)
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
# huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
which(is.na(poploss_keyser) == FALSE)
c(which(is.na(poploss_keyser) == FALSE))
huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE))]
dim(huegenots.data)
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE)),]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE)),]
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
W <- cbind(1, ln_workers1802_all, ln_looms1802_all, mi_ln_input1802_all, no_looms,
ln_popcity1802, vieh1816_schaf_ganz_veredelt_pc, pop1816_prot_pc, no_hugue_possible, imputed_dummy, textil_1680_dummy)
control.variables <-lmrob.control()
control.variables$k.max <- 100000
control.variables$refine.tol <- 1e-10
summary(lmrob(Y ~ 0 + Z + W,
control = control.variables))
pairs(cbind(Y,X,Z))
beta_grid = seq(-0.1, 0.3, 0.01)
conf_set_robust = rep(-Inf, length(beta_grid))
# lev_mat <- cbind(W,Z)
# H_mat <- lev_mat %*% solve(t(lev_mat) %*% lev_mat) %*% t(lev_mat)
gewichtjes <- rep(1, length(Y))
for(i in 1:length(beta_grid)){
dep_var <- Y - X * beta_grid[i]
full_model <- lm(dep_var ~ 1 + ln_workers1802_all + ln_looms1802_all + mi_ln_input1802_all + no_looms+
ln_popcity1802+ vieh1816_schaf_ganz_veredelt_pc+ pop1816_prot_pc+ no_hugue_possible+
imputed_dummy+ textil_1680_dummy + poploss_keyser)
res_model <- lm(dep_var ~ 1 + ln_workers1802_all + ln_looms1802_all + mi_ln_input1802_all + no_looms+
ln_popcity1802+ vieh1816_schaf_ganz_veredelt_pc+ pop1816_prot_pc+ no_hugue_possible+ imputed_dummy+ textil_1680_dummy)
rob_model <- lmrob(formula = full_model, control = control.variables, method = "MM")
estScale <- rob_model$scale
full.model = full_model
restricted.model = res_model
scale.est = estScale
weight.vector = gewichtjes
tukey.c = 4.68
tau_stat = RobustScoreTest(full_model,
res_model,
estScale,
gewichtjes,
tukey.c = 4.68)
if(tau_stat$W.statistic < qchisq(0.95,1)){
conf_set_robust[i] <- beta_grid[i]
}
}
conf_set_robust
ivmodel(Y, X, Z, W)
head(W)
dim(huegenots.data)
library(robustbase)
library(readstata13) # need this to load in stata dta file
library(ivmodel) # need this for AR test
library(robustX) # need this for Bacon algorithm
source("RobustScoreTest.R")
huegenots.data <- read.dta13("C:/Users/73051jkl/OneDrive - Erasmus University Rotterdam/Desktop/weak instruments tests/huegenots.dta")
for(i in 1:length(names(huegenots.data))){
name = names(huegenots.data)[i]
assign(name, huegenots.data[[i]])
}
# huegenots.data <- huegenots.data[-c(which(is.na(poploss_keyser) == FALSE)),]
# for(i in 1:length(names(huegenots.data))){
#   name = names(huegenots.data)[i]
#   assign(name, huegenots.data[[i]])
# }
Y <- ln_output1802_all
X <- hugue_1700_pc
Z <- poploss_keyser
W <- cbind(1, ln_workers1802_all, ln_looms1802_all, mi_ln_input1802_all, no_looms,
ln_popcity1802, vieh1816_schaf_ganz_veredelt_pc, pop1816_prot_pc, no_hugue_possible, imputed_dummy, textil_1680_dummy)
control.variables <-lmrob.control()
control.variables$k.max <- 100000
control.variables$refine.tol <- 1e-10
summary(lmrob(Y ~ 0 + Z + W,
control = control.variables))
pairs(cbind(Y,X,Z))
beta_grid = seq(-0.1, 0.3, 0.01)
conf_set_robust = rep(-Inf, length(beta_grid))
# lev_mat <- cbind(W,Z)
# H_mat <- lev_mat %*% solve(t(lev_mat) %*% lev_mat) %*% t(lev_mat)
gewichtjes <- rep(1, length(Y))
for(i in 1:length(beta_grid)){
dep_var <- Y - X * beta_grid[i]
full_model <- lm(dep_var ~ 1 + ln_workers1802_all + ln_looms1802_all + mi_ln_input1802_all + no_looms+
ln_popcity1802+ vieh1816_schaf_ganz_veredelt_pc+ pop1816_prot_pc+ no_hugue_possible+
imputed_dummy+ textil_1680_dummy + poploss_keyser)
res_model <- lm(dep_var ~ 1 + ln_workers1802_all + ln_looms1802_all + mi_ln_input1802_all + no_looms+
ln_popcity1802+ vieh1816_schaf_ganz_veredelt_pc+ pop1816_prot_pc+ no_hugue_possible+ imputed_dummy+ textil_1680_dummy)
rob_model <- lmrob(formula = full_model, control = control.variables, method = "MM")
estScale <- rob_model$scale
full.model = full_model
restricted.model = res_model
scale.est = estScale
weight.vector = gewichtjes
tukey.c = 4.68
tau_stat = RobustScoreTest(full_model,
res_model,
estScale,
gewichtjes,
tukey.c = 4.68)
if(tau_stat$W.statistic < qchisq(0.95,1)){
conf_set_robust[i] <- beta_grid[i]
}
}
conf_set_robust
ivmodel(Y, X, Z, W)
NA + 1
install.packages("grf")
library(grf)
library(grf)
instrumental_forest(Y = Y, X = X, Z = Z
)
library(robustbase)
library(robustX)
library(readstata13)
library(ivmodel) # need this for AR test
library(riv) # robust IV estimator
source("RobustScoreTest.R")
fiscal.data <- read.dta13("EmpiricalExamples/FiscalRelief.dta")
fiscal.data <- fiscal.data[-outliers,]
for(i in 1:length(names(fiscal.data))){
name = names(fiscal.data)[i]
assign(name, fiscal.data[[i]])
}
Y <- sachange_gov_broad_pc
X <- fmap_pc
Z <- instrument_pc
# Use Bacon Algorithm to find outliers.
BC <- BACON(cbind(Y, X, Z),
alpha = 0.01)
outliers <- which(BC$subset*1 == 0)
bacon.weights <- BC$subset*1
pairs(cbind(Y, X, Z),
labels = c("y2", "y1", "x2"))
pairs.data <- data.frame(Y, X, Z, bacon.weights)
group <- NA
group[pairs.data$bacon.weights == 0] <- 1
group[pairs.data$bacon.weights != 0] <- 2
group
# Makes a plot where the outliers are in red
pairs(pairs.data[, 1:3],
col = c("red", "cornflowerblue", "darkred")[group],
pch = c(8, 1)[group],
labels = c("y2", "y1", "x2"))
# use this to find first stage F-statistic
summary(lm(X ~ 1 + Z))
beta_grid = seq(-2, 3, 0.01)
conf_set_robust = rep(-Inf, length(beta_grid))
a1<-lmrob.control()
a1$k.max <- 100000
a1$maxit.scale <- 100000
a1$max.it <- 500
gewichtjes <- sqrt(1 - diag(Z %*% solve(t(Z) %*% Z) %*% t(Z)))
p_values = rep(1, length(beta_grid))
for(i in 1:length(beta_grid)){
dep_var = Y - X * beta_grid[i]
full_model <- dep_var ~ 1 + Z
res_model <- dep_var ~ 1
rob_model <- lmrob(formula = full_model, control = a1, method = "MM")
estScale <- rob_model$scale
tau_stat = RobustScoreTest(full_model,
res_model,
estScale,
gewichtjes,
tukey.c = 4.68)
if(tau_stat$W.statistic < qchisq(0.90,1)){
conf_set_robust[i] <- beta_grid[i]
}
p_values[i] <- tau_stat$p.value
if(tau_stat$W.statistic < qchisq(0.95,1)){
conf_set_robust[i] <- beta_grid[i]
}
}
conf_set_robust
AR.test(ivmodel(Y, X, Z), alpha = 0.1)$ci
riv(Y, X, Zinst = Z)$Summary.Table
ivmodel(Y, X, Z)
plot(p_values)
lines(rep(0.1, length(beta_grid)))
beta_grid[which(p_values == max(p_values))]
instrumental_forest(Y = Y, X = X, Z = Z
)
library(robustbase)
library(robustX)
library(readstata13)
library(ivmodel) # need this for AR test
library(riv) # robust IV estimator
source("RobustScoreTest.R")
fiscal.data <- read.dta13("EmpiricalExamples/FiscalRelief.dta")
fiscal.data <- fiscal.data[-outliers,]
for(i in 1:length(names(fiscal.data))){
name = names(fiscal.data)[i]
assign(name, fiscal.data[[i]])
}
Y <- sachange_gov_broad_pc
X <- fmap_pc
Z <- instrument_pc
# Use Bacon Algorithm to find outliers.
BC <- BACON(cbind(Y, X, Z),
alpha = 0.01)
outliers <- which(BC$subset*1 == 0)
bacon.weights <- BC$subset*1
pairs(cbind(Y, X, Z),
labels = c("y2", "y1", "x2"))
pairs.data <- data.frame(Y, X, Z, bacon.weights)
group <- NA
group[pairs.data$bacon.weights == 0] <- 1
group[pairs.data$bacon.weights != 0] <- 2
group
# Makes a plot where the outliers are in red
pairs(pairs.data[, 1:3],
col = c("red", "cornflowerblue", "darkred")[group],
pch = c(8, 1)[group],
labels = c("y2", "y1", "x2"))
# use this to find first stage F-statistic
summary(lm(X ~ 1 + Z))
beta_grid = seq(-2, 3, 0.01)
conf_set_robust = rep(-Inf, length(beta_grid))
a1<-lmrob.control()
a1$k.max <- 100000
a1$maxit.scale <- 100000
a1$max.it <- 500
gewichtjes <- sqrt(1 - diag(Z %*% solve(t(Z) %*% Z) %*% t(Z)))
p_values = rep(1, length(beta_grid))
for(i in 1:length(beta_grid)){
dep_var = Y - X * beta_grid[i]
full_model <- dep_var ~ 1 + Z
res_model <- dep_var ~ 1
rob_model <- lmrob(formula = full_model, control = a1, method = "MM")
estScale <- rob_model$scale
tau_stat = RobustScoreTest(full_model,
res_model,
estScale,
gewichtjes,
tukey.c = 4.68)
if(tau_stat$W.statistic < qchisq(0.90,1)){
conf_set_robust[i] <- beta_grid[i]
}
p_values[i] <- tau_stat$p.value
if(tau_stat$W.statistic < qchisq(0.95,1)){
conf_set_robust[i] <- beta_grid[i]
}
}
conf_set_robust
AR.test(ivmodel(Y, X, Z), alpha = 0.1)$ci
riv(Y, X, Zinst = Z)$Summary.Table
ivmodel(Y, X, Z)
plot(p_values)
lines(rep(0.1, length(beta_grid)))
beta_grid[which(p_values == max(p_values))]
instrumental_forest(Y = Y, X = X, Z = Z,
W = Z)
instrumental_forest(as.matrix(Y), as.matrix(X), as.matrix(Z))
instrumental_forest(as.matrix(Y), as.matrix(X), as.matrix(Z), as.matrix(Z))
1
instrumental_forest(as.matrix(Y), as.matrix(X),Z = as.matrix(Z))
instrumental_forest(Y = Y, X = X, Z = Z
)
instrumental_forest(Y = as.matrix(Y), X = as.matrix(X), Z = as.matrix(Z), W = as.matrix(Z)
)
library(robustbase)
library(readstata13)
library(ivmodel)
library(robustX)
library(riv)
source("RobustScoreTest.R")
ananat.data <- read.dta13("EmpiricalExamples/aej_maindata.dta")
# ananat.data <- ananat.data[-outliers,]
# ananat.data <- ananat.data[-c(6),]
# Here we load in the variables
for(i in 1:length(names(ananat.data))){
name = names(ananat.data)[i]
assign(name, ananat.data[[i]])
}
#Here we use the general IV notation
Y <- lngini_w
# Y <- povrate_w
Z <- herf
X <- dism1990
W <- cbind(1, lenper)
L <- c(lenper)
# MW <- (diag(1, length(Y)) - W %*% solve(t(W) %*% W) %*% t(W))
#
# Z <- MW %*% Z
# X <- MW %*% X
# Y <- MW %*% Y
# outlier detection
BC <- BACON(cbind(Y, X, Z, lenper),
alpha = 0.01)
outliers <- which(BC$subset*1 == 0)
bacon.weights <- BC$subset*1
pairs(cbind(Y, X, Z, lenper),
col = "cornflowerblue",
labels = c("y2", "y1", "x2", "x1"))
pairs.data <- data.frame(Y, X, Z, lenper, bacon.weights)
group <- NA
group[pairs.data$bacon.weights == 0] <- 1
group[pairs.data$bacon.weights != 0] <- 2
group
pairs(pairs.data[, 1:4],
col = c("red", "cornflowerblue", "darkred")[group],
pch = c(8, 1)[group],
labels = c("y2", "y1", "x2", "x1"))
# a1<-lmrob.control()
# a1$k.max <- 200000
# # a1$maxit.scale <- 100000
# # a1$max.it = 50000
H_matrix <- cbind(1, Z, L)
gewichtjes <- sqrt(1 - diag(H_matrix %*% solve(t(H_matrix) %*% H_matrix) %*% t(H_matrix)))^6
# gewichtjes <- sqrt(1 - diag(H_matrix %*% solve(t(H_matrix) %*% H_matrix) %*% t(H_matrix)))
# gewichtjes <- rep(1, length(herf))
# gewichtjes[6] = 0
# gewichtjes[22] <- 0
# data_mat <- cbind(Z,L)
# covMcd.obj <- covMcd(data_mat)
# rob_mean <- covMcd.obj$center
# rob_cov <- covMcd.obj$cov
# gewichtjes <- pmin(1, 3.84/sqrt(mahalanobis(data_mat, rob_mean, rob_cov)))
# gewichtjes[6] <- 0
# we can use this to find the first stage F statistic
f.stat = summary(lm(dism1990 ~ 1 + lenper + herf))
robust.f.stat = RobustScoreTest(dism1990 ~ 1 + lenper + herf,
dism1990 ~ 1 + lenper,
lmrob(dism1990 ~ 1 + lenper)$scale,
gewichtjes)
# Now compute the confidence interval
beta_grid = seq(-10, 10, 0.1)
conf_set_robust = rep(-Inf, length(beta_grid))
p_values = rep(1, length(beta_grid))
control.variables <-lmrob.control()
control.variables$k.max <- 100000
control.variables$refine.tol <- 1e-10
for(i in 1:length(beta_grid)){
dep_var = Y - beta_grid[i]*X
full_model <-  dep_var ~ 1 + lenper + Z
res_model  <-  dep_var ~ 1 + lenper
tau_stat = RobustScoreTest(full_model,
res_model,
lmrob(dep_var ~ 1 + lenper + Z,
weights = gewichtjes,
control = control.variables)$scale,
# rlm(dep_var ~ 1 + lenper + Z,
#     weights = as.vector(gewichtjes))$s,
gewichtjes,
tukey.c = 4.68)
p_values[i] <- tau_stat$p.value
if(tau_stat$W.statistic < qchisq(0.95,1)){
conf_set_robust[i] <- beta_grid[i]
}
}
conf_set_robust
AR.test(ivmodel(Y, X, Z, L))$ci
ivmodel(Y, X, Z, L)
riv(Y, X, Xex = W[,2], Zinst = Z)$Summary.Table
plot(p_values)
lines(rep(0.05, length(beta_grid)))
beta_grid[which(p_values == max(p_values))]
instrumental_forest(Y = as.matrix(Y), X = cbind(X, lenper), Z = as.matrix(Z), W = as.matrix(Z)
)
iv.forest <- instrumental_forest(Y = as.matrix(Y), X = cbind(X, lenper), Z = as.matrix(Z), W = as.matrix(Z)
)
predict(iv.forest)
causal_forest(Y = as.matrix(Y), X = cbind(X, lenper), W = as.matrix(Z))
median(predict(iv.forest, estimate.variance = TRUE)$variance.estimates, na.rm = TRUE)
mean(predict(iv.forest, estimate.variance = TRUE)[,1])
mean(predict(iv.forest, estimate.variance = TRUE)[,2])
ivmodel(Y, X, Z, L)
